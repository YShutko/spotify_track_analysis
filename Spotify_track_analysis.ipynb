{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99d93488",
   "metadata": {},
   "source": [
    "# Spotify Track Analytics Popularity Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5875eb",
   "metadata": {},
   "source": [
    "Dataset Content\n",
    "The data set used for this project: [Kaggle](https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset). The collection of ~114,000 songs across 125 genres with features like danceability, energy, tempo, and popularity. Ideal for audio analysis, genre classification, and music trend exploration.\n",
    "\n",
    "The dataset consists of the following columns:\n",
    "\n",
    "* track_id: Unique Spotify identifier for each track.\n",
    "* artists: List of artists performing the track, separated by semicolons.\n",
    "* album_name: Title of the album where the track appears.\n",
    "* track_name: Title of the song.\n",
    "* popularity: Score from 0‚Äì100 based on recent play counts; higher means more popular.\n",
    "* duration_ms: Length of the track in milliseconds.\n",
    "* explicit: Indicates whether the track contains explicit content (True/False).\n",
    "* danceability: Score (0.0‚Äì1.0) measuring how suitable the song is for dancing.\n",
    "* energy: Score (0.0‚Äì1.0) reflecting intensity, speed, and loudness.\n",
    "* key: Musical key using Pitch Class notation (0 = C, 1 = C‚ôØ/D‚ô≠, etc.).\n",
    "* loudness: Overall volume of the track in decibels.\n",
    "* mode: Indicates scale type (1 = major, 0 = minor).\n",
    "* speechiness: Score estimating spoken content in the track.\n",
    "* cousticness: Likelihood (0.0‚Äì1.0) that the song is acoustic.\n",
    "* instrumentalness: Probability that the track has no vocals.\n",
    "* liveness: Measures if the song was recorded live (higher = more live).\n",
    "* valence: Positivity of the music (0.0 = sad, 1.0 = happy).\n",
    "* tempo: Speed of the song in beats per minute (BPM). time_signature: Musical meter (e.g. 4 = 4/4 time). * track_genre: Musical genre classification of the track."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82280296",
   "metadata": {},
   "source": [
    "Import libraries that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7a5b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd                 #import Pandas for data manipulation\n",
    "import numpy as np                  #import Numpy for numerical operations\n",
    "import matplotlib.pyplot as plt     #import Matplotlib for data visualization\n",
    "import seaborn as sns               #import Seaborn for statistical data visualization\n",
    "from plotly.subplots import make_subplots  #import Plotly subplots for creating complex figures\n",
    "import plotly.express as px         #import Plotly Express for interactive visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366a744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")                  # Set Seaborn style for plots\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)     # Set default figure size for Matplotlib plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c722c6c",
   "metadata": {},
   "source": [
    "## 1. Explanatory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ab6a12",
   "metadata": {},
   "source": [
    "In this section EDA, including data load and cleaning, is performed.\n",
    "As a first step, data set is loaded into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4841ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/spotify_dataset.csv')  # Load the car price dataset\n",
    "df.head()                                            # Display the first few rows of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2998ac4",
   "metadata": {},
   "source": [
    "### 1.1.Initial data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7d2c25",
   "metadata": {},
   "source": [
    "In the following subsection initial data set inspection is performed. Here the shape and Info of DataFrame are shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431e1d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)                     # Print the shape of the DataFrame           \n",
    "print(df.info())                    # Print concise summary of the DataFrame            \n",
    "print(df.dtypes)                    # Print data types of each column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500a6182",
   "metadata": {},
   "source": [
    "This dataset contains of 114 entires and 21 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8937131",
   "metadata": {},
   "source": [
    "In the next steps DataFrame is checked for any incosistencies(dublicates, missing value and etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52dac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()                  # Check for missing values in each column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d809468c",
   "metadata": {},
   "source": [
    "As it is can be seen, there are 3 empty etries. This number is neglectable, so we can drop these entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b3a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "df. dropna(inplace=True)          # Drop rows with missing values\n",
    "df.reset_index(drop=True, inplace=True)  # Reset index after dropping rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0040131c",
   "metadata": {},
   "source": [
    "and veryfying, that empty values are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce61e756",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()                  # Verify that there are no missing values left"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79953a8",
   "metadata": {},
   "source": [
    "here column names are displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88e4273",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b7faf6",
   "metadata": {},
   "source": [
    "here we see that we have column \"Unnamed:0\" and \"track_id\". These two columns are not important for further analysis and modeling, therefore they can be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa58f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['Unnamed: 0', 'track_id'], inplace=True)  # Drop unnecessary columns and display the first few rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b6782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb7ab40",
   "metadata": {},
   "source": [
    "1. Detects duplicates\n",
    "2. Prints total count\n",
    "3. Displays which rows are duplicated (track name, artist, album)\n",
    "4. Shows which columns differ across duplicates\n",
    "5. Removes duplicates and saves the clean dataset into data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3a4c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Detect duplicates\n",
    "duplicates = df[df.duplicated(keep=False)]\n",
    "print(\"üîÅ Number of duplicate records:\", len(duplicates))\n",
    "\n",
    "# Step 2: Show duplicate track details\n",
    "if not duplicates.empty:\n",
    "    print(\"\\nüìÄ Duplicated Tracks (sample):\")\n",
    "    print(duplicates[['track_name', 'artists', 'album_name']].head())\n",
    "\n",
    "    # Step 3: Compare duplicates to first occurrence\n",
    "    print(\"\\nüîé Columns with different values in duplicated rows:\")\n",
    "    duplicated_indices = duplicates.index\n",
    "\n",
    "    for idx in duplicated_indices:\n",
    "        row = df.loc[idx]\n",
    "        first_occurrence = df[(df['track_name'] == row['track_name']) & \n",
    "                              (df['artists'] == row['artists']) & \n",
    "                              (df['album_name'] == row['album_name'])].iloc[0]\n",
    "        \n",
    "        differing_columns = [col for col in df.columns if row[col] != first_occurrence[col]]\n",
    "\n",
    "        if differing_columns:\n",
    "            print(f\"Row {idx} differs in columns: {differing_columns}\")\n",
    "\n",
    "# Step 4: Remove duplicate rows (keeping the first occurrence)\n",
    "df= df[~df.duplicated()]\n",
    "print(\"\\n‚úÖ Duplicate records removed. Cleaned dataset ready in `data`.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae8238e",
   "metadata": {},
   "source": [
    "For further simplicity, categorical and numerical columns were splitted. also column \"explicit\" set as numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cf3994",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['explicit'] = df['explicit'].astype(int)  # Convert 'explicit' column to integer type\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist() # Select categorical columns\n",
    "numerical_cols = df.select_dtypes(include=['number']).columns.tolist()              # Select numerical columns\n",
    "\n",
    "print(\"Categorical columns:\")\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cb59b2",
   "metadata": {},
   "source": [
    "The next step is to make names unified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035ad0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each categorical column and clean it\n",
    "for col in categorical_cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        .astype(str)                 # ensure the column is string type\n",
    "        .str.strip()                 # remove leading/trailing spaces\n",
    "        .str.lower()                 # make everything lowercase\n",
    "        .str.replace(\"-\", \" \", regex=False)   # replace hyphens with spaces\n",
    "        .str.replace(\"_\", \" \", regex=False)   # replace underscores with spaces\n",
    "        .str.replace(\";\", \" and \", regex=False)   # replace semicolons with spaces\n",
    "    )\n",
    "\n",
    "# Check the result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee4ecc2",
   "metadata": {},
   "source": [
    "Detecting misspellings or inconsistent categories in categorical columns is super important for EDA and modeling (e.g., \"hip hop\" vs \"Hip-Hop\" vs \"Hip hop\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7056dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_cols:      # Loop through each categorical column\n",
    "    print(f\"\\nüîπ Column: {col}\")                   \n",
    "    print(f\"Unique values: {df[col].nunique()}\")  # Print number of unique categories\n",
    "    print(df[col].value_counts())  # Show top 10 most common categories\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9d17cb",
   "metadata": {},
   "source": [
    "This gives you an overview of what‚Äôs inside each categorical column ‚Äî letting you visually spot potential misspellings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29674d82",
   "metadata": {},
   "source": [
    "It is also nessecary to convert song duration from milliseconds to mintues and drop \"duration_ms\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb862d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"duration_min\"] = df[\"duration_ms\"] / 60000  # Convert duration from milliseconds to minutes\n",
    "df.drop(columns=[\"duration_ms\"], inplace=True)  # Drop the original duration_ms column\n",
    "df.head()  # Display the first few rows to verify changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ea526c",
   "metadata": {},
   "source": [
    "Next step is to take a look on a descriptive statistic summary for each column in the df.\n",
    "\n",
    "We use descriptive statistics to summarize, explore, and validate the dataset before modeling. They give us a quick overview of central tendencies, spread, and anomalies ‚Äî helping us decide how to clean, visualize, and model the data.\n",
    "\n",
    "This summary includes following metrics:\n",
    "\n",
    "* count: Number of non-missing (non-NaN) values. Helps check missing data.\n",
    "* mean: Average (sum / count). Central tendency of numeric data.\n",
    "* std: Standard deviation. How spread out the values are from the mean.\n",
    "* min: Minimum value. The smallest observed value.\n",
    "* 25%: 25th percentile (Q1). 25% of data is below this value\n",
    "* 50% (median): 50th percentile. Half the data is below this value.\n",
    "* 75%: 75th percentile (Q3). 75% of data is below this value\n",
    "* max: Maximum value. The largest observed value\n",
    "In following cell a descriptive statistics of numeric columns is performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21ccec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # Generate descriptive statistics of numerical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676a1f1e",
   "metadata": {},
   "source": [
    "The dataset contains 113,999 tracks, and the statistics cover 14 numerical features related to track popularity and audio characteristics.\n",
    "\n",
    "Key Feature Insights\n",
    "1. Popularity\n",
    "Range: 0 to 100 (Spotify-defined scale). Mean: 33.2 (relatively low), Median: 35.\n",
    "Insight: Majority of songs in the dataset are not highly popular. Only a small portion reaches scores above 75.\n",
    "2. Danceability\n",
    "Scale: 0.0 to 1.0 (higher = more danceable). Mean: 0.567.\n",
    "Insight: Most tracks are moderately danceable. Distribution is slightly right-skewed with many songs in the 0.5‚Äì0.7 range.\n",
    "3. Energy\n",
    "Scale: 0.0 to 1.0. Mean: 0.64.\n",
    "Insight: Tracks generally have high energy, indicating a tendency toward upbeat or intense music.\n",
    "4. Key\n",
    "Range: 0 to 11 (12 semitones, C to B). Mean: ~5.3.\n",
    "Insight: Keys are evenly distributed, with slight clustering near 5 (F major / D minor).\n",
    "5. Loudness\n",
    "Unit: Decibels (dB). Mean: -8.26 dB, Min: -49.5 dB.\n",
    "Insight: Some tracks have extremely low loudness, possibly ambient or silent tracks; majority are mastered for streaming loudness levels (around -7 dB).\n",
    "6. Mode\n",
    "Binary: 0 = minor, 1 = major. Mean: 0.637 ‚Üí ~64% of songs are in major mode.\n",
    "Insight: Major mode dominates (typically associated with ‚Äúhappy‚Äù sound).\n",
    "7. Speechiness\n",
    "Scale: 0.0 to 1.0. Mean: 0.084.\n",
    "Insight: Most tracks have low speech content (e.g., songs, not podcasts), but the max of 0.965 suggests some spoken word/music hybrids.\n",
    "8. Acousticness\n",
    "Mean: 0.315. Insight: Majority of tracks are not acoustic-heavy, but the high standard deviation (0.33) shows some variety.\n",
    "9. Instrumentalness\n",
    "Mean: 0.156. \n",
    "Insight: Most tracks contain vocals (median ~0.000042), but there‚Äôs a small but significant subset of instrumental music.\n",
    "10. Liveness\n",
    "Mean: 0.213.\n",
    "Insight: Most tracks are studio recordings; live recordings are rare.\n",
    "11. Valence\n",
    "Scale: 0.0 (sad) to 1.0 (happy).\n",
    "Mean: 0.47.\n",
    "Insight: Balanced distribution between positive and negative mood songs.\n",
    "12. Tempo\n",
    "Mean: 122 BPM. \n",
    "Insight: Common tempo for pop/dance tracks. Range is wide (0‚Äì243 BPM), but the quartiles (25% = 99 BPM, 75% = 140 BPM) confirm a core BPM range of ~100‚Äì140.\n",
    "13. Time Signature\n",
    "Mean: ~3.9. \n",
    "Insight: Most tracks are in 4/4 time (common time), as expected. Very little variation.\n",
    "14. Duration (in minutes)\n",
    "Mean: 3.8 minutes. \n",
    "Max: 87 minutes!\n",
    "Insight: Typical track duration matches mainstream standards. Max suggests presence of podcasts, live sets, or compilation tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe3cec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.copy()  # Create a copy of the cleaned DataFrame\n",
    "df_cleaned.to_csv('data/spotify_cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6b850f",
   "metadata": {},
   "source": [
    "### 1.2 Initial data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ce4589",
   "metadata": {},
   "source": [
    "In this section initial data visualisation is performed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0884696c",
   "metadata": {},
   "source": [
    "1.2.1 Pairplot of key numerical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf36440e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
